{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decaf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "from cs336_basics.myModule import toy_Dataloader\n",
    "from cs336_basics.myModule import toy_Transformer_lm\n",
    "from cs336_basics.myOptimizer import toy_AdamW\n",
    "from cs336_basics.myFunctional import toy_cross_entry, slow_generate, save_check_point , load_check_point, cosine_warm_up_lr, toy_grad_clip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "vocab_path = \"/root/workspace/cs336/assignment2/my_output/vocab.json\"\n",
    "merges_path = \"/root/workspace/cs336/assignment2/my_output/merges.txt\"\n",
    "train_data_path = \"/root/workspace/cs336/assignment1/data/TinyStoriesV2-GPT4-train.txt\"\n",
    "val_data_path = \"/root/workspace/cs336/assignment1/data/TinyStoriesV2-GPT4-valid.txt\"\n",
    "weight_path = \"/root/workspace/cs336/assignment2/my_output/weights/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [\"/root/workspace/cs336/assignment1/data/TinyStoriesV2-GPT4-train.txt\"]\n",
    "# tokenizer = ByteLevelBPETokenizer()\n",
    "# tokenizer.train(\n",
    "#     files=files,\n",
    "#     vocab_size=10_000,\n",
    "#     min_frequency=2,\n",
    "#     special_tokens=[\"<|endoftext|>\"],\n",
    "# )\n",
    "\n",
    "# tokenizer.save_model(\"/root/workspace/cs336/assignment1/my_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75809001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = ByteLevelBPETokenizer(vocab_path, merges_path)\n",
    "tok.add_special_tokens([AddedToken(\"<|endoftext|>\", special=True)])\n",
    "tok.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0d8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "vocab_size = tok.get_vocab_size()\n",
    "max_context_len = 256\n",
    "d_model = 768\n",
    "d_ff = 3072\n",
    "theta = 10000\n",
    "num_layer = 12\n",
    "num_heads = 12 \n",
    "\n",
    "batch_size = 4\n",
    "#train_round = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e532eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = toy_Dataloader(train_data_path, tok, max_context_len,4*batch_size ,device)\n",
    "val_data_loader = toy_Dataloader(val_data_path, tok, max_context_len, 4*batch_size, device)\n",
    "model = toy_Transformer_lm(vocab_size,max_context_len,d_model,num_layer,num_heads,d_ff,theta,device).to(device)\n",
    "opt = toy_AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_contetxt = \"Once upon a time, there is a cat Tina\"\n",
    "# generate_len = 50\n",
    "# max_lr = 1e-3\n",
    "# min_lr = 4e-4\n",
    "# warm_up_iter = 500\n",
    "# cos_end_iter = train_round - warm_up_iter\n",
    "# #Train Loop\n",
    "# for iter in range(train_round):\n",
    "#     data,target = train_data_loader.get_batch(batch_size)\n",
    "#     out = model(data)\n",
    "#     loss = toy_cross_entry(out,target)\n",
    "#     opt.zero_grad()\n",
    "#     loss.backward()\n",
    "#     opt.step(lr_new=cosine_warm_up_lr(iter,max_lr,min_lr,warm_up_iter,cos_end_iter))\n",
    "#     toy_grad_clip(model.parameters(),device = model.device)\n",
    "#     if iter%100 == 0:\n",
    "#         with torch.no_grad():\n",
    "#             val_data, val_target = val_data_loader.get_batch(batch_size)\n",
    "#             val_out = model(val_data)\n",
    "#             val_loss = toy_cross_entry(val_out,val_target)\n",
    "#             print(\"iter:{},loss:{},val_loss:{},lr:{}\".format(iter,loss,val_loss,opt.param_groups[0][\"lr\"]))\n",
    "#             print(slow_generate(model, tok, test_contetxt, generate_len))\n",
    "#     if iter%10000 == 0:\n",
    "#         save_path = weight_path + \"model_{}.pt\".format(iter)\n",
    "#         save_check_point(model, opt, iter, save_path)\n",
    "# train_data_loader.close()    \n",
    "# print(slow_generate(model, tok, test_contetxt, generate_len))\n",
    "# save_path = weight_path + \"model_final.pt\"\n",
    "# save_check_point(model, opt, train_round, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0c4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_up_iter = 10\n",
    "test_iter = 10\n",
    "totol_iter = warm_up_iter + test_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd382354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward time: 0.03956387330017606, backward time: 0.11055371279999235\n"
     ]
    }
   ],
   "source": [
    "data_0,target_0 = train_data_loader.get_batch(batch_size)\n",
    "forward_times = []\n",
    "total_times = []\n",
    "for iter in range(warm_up_iter):\n",
    "    out = model(data_0)\n",
    "    loss = toy_cross_entry(out,target_0)\n",
    "    torch.cuda.synchronize()\n",
    "for iter in range(test_iter):\n",
    "    t0 = timeit.default_timer()\n",
    "    out = model(data_0)\n",
    "    loss = toy_cross_entry(out,target_0)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = timeit.default_timer()\n",
    "    dt = t1 - t0\n",
    "    forward_times.append(dt)\n",
    "    \n",
    "for iter in range(warm_up_iter):\n",
    "    out = model(data_0)\n",
    "    loss = toy_cross_entry(out,target_0)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "for iter in range(test_iter):\n",
    "    t0 = timeit.default_timer()\n",
    "    out = model(data_0)\n",
    "    loss = toy_cross_entry(out,target_0)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = timeit.default_timer()\n",
    "    dt = t1 - t0\n",
    "    total_times.append(dt)\n",
    "print(\"forward time: {}, backward time: {}\".format(sum(forward_times)/test_iter, sum(total_times)/test_iter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
